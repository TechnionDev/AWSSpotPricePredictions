{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f1da17",
   "metadata": {},
   "source": [
    "# AWS Spot Price Predictions\n",
    "\n",
    "## AWS Spot Instances\n",
    "\n",
    "Amazon EC2 Spot Instances let you take advantage of unused EC2 capacity in the AWS cloud. Spot Instances are available at up to a 90% discount compared to On-Demand prices.\n",
    "\n",
    "According to Amazon, Spot instances can be used to stateless/fault-tolerant/flexible worklouds. The idea it to provide machines for much lower prices while promising no guarantees regarding how long the machine will be available, providing only 60 seconds notice before terminating the machine.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a309b",
   "metadata": {},
   "source": [
    "## Goals\n",
    "The idea is to use the discounts Spot instances provide to minimize the cost of cloud workloads. To achieve that, we want to predict both price changes and upcoming interruptions. Thus providing the workload with enough time to gracefully hand over resources and safely shutting down the machine with minimal loss of progress.\n",
    "\n",
    "So the main 2 goals are:\n",
    "- Provide predictions for Spot price changes\n",
    "- Provide predictions for upcoming interruptions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a4af93",
   "metadata": {},
   "source": [
    "## Data Fetching\n",
    "\n",
    "For the ML models we needed as much data as possible. Some of the data was provided to us (`spotData.csv`) and some we tried to fetch ourselves.\n",
    "\n",
    "We created a script `simple_history_log.py` that fetches as much data as possible using the AWS API (called `boto3`). The script concurrently (for different regions) fetches data from the last 3 months (that's all the API can provide) from most recent to oldest. Since the script takes a long time to run, we added a mechanism to save the progress periodically as well as let the script continue where it left off.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933c487",
   "metadata": {},
   "source": [
    "### The Fetching Proccess using `boto3`\n",
    "Since, naturally, there is a lot of data in a span of 3 months, the API returns a single \"page\" (chunk) of data for each API request. In the response, there's a `next_token` which we need to provide for the next request to get the next chunk of data. Thus, the fetching per region needs to be done in a serial manner.\n",
    "Each respone is a json in the following format:\n",
    "```json\n",
    "{\n",
    "    'NextToken': '<base64_token>',\n",
    "    'ResponseMetadata': {/* We don't really care about that */},\n",
    "    'SpotPriceHistory': [\n",
    "        /* Timestamped entries. Each entry is for a specific machine, OS and region. It contains the timestamp and the price */\n",
    "        {\n",
    "            'AvailabilityZone': 'eu-north-1b',\n",
    "            'InstanceType': 'r5n.12xlarge',\n",
    "            'ProductDescription': 'Windows',\n",
    "            'SpotPrice': '2.928700',\n",
    "            'Timestamp': datetime.datetime(2022, 3, 9, 20, 35, 8, tzinfo=tzutc())\n",
    "         },\n",
    "         ...\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c2481",
   "metadata": {},
   "source": [
    "\n",
    "It is also important to note that it's not 100% clear what is the exact meaning of the data we are fetching. Sometimes we can get big gaps between data points (timestamp wise. For example we might not see any data for an instance between Feb 10th until Feb 12th). \n",
    "At first we thought the API only provides a data spot when the price changes but then we noticed there are sometimes very sequential data point with very minimal time gaps (seconds sometimes) with identical prices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ee943",
   "metadata": {},
   "source": [
    "\n",
    "We couldn't find any definite explanation for the phenomenon but here are a few theories that might be worth exploring:\n",
    "1. The big gaps mean the machine was not available at all as a Spot instance at that time\n",
    "2. The prices were changing but with such minor changes that the precision isn't fine enough to show it (i.e. the backend sends a data point because it detected a change but after server-side rounding, the data point is identical to the last one)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d71316b",
   "metadata": {},
   "source": [
    "\n",
    "We found contradicting examples for each of those but we might be missing something.\n",
    "For example we expected to see a very recent timestamp data point for an available Spot machine (if theory 1 is correct) but we didn't always see that, we noticed at times relatively old data points that are aligned with the current unchanged price.\n",
    "We didn't explore theory 2 enough to say.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da5fd89",
   "metadata": {},
   "source": [
    "\n",
    "It's also unclear whether or not a data point will be provided when the machine isn't even available. Also, we don't know what is the precision of this data and if it \"catches\" all of the changes.\n",
    "\n",
    "Another weird thing was that the `boto3` only **usually** gave us the data point sorted by data. Meaning, sometimes we could get a data point for the 10th then 11th and then 10th again. Although rare, it did happen.\n",
    "\n",
    "We continued with those unknowns in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cd272",
   "metadata": {},
   "source": [
    "### Fetching from Spot Advisor\n",
    "\n",
    "Amazon provides that shows the last month's averages of savings and interruptions: https://aws.amazon.com/ec2/spot/instance-advisor/\n",
    "\n",
    "We wanted to watch the webpage for changes over time and from slight changes build finer data. We created a script to watch that page `get_int_json.[py|sh]` but since the data provided by this page is merely rough estimates, the small changes didn't reflect as we hoped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe10ab7",
   "metadata": {},
   "source": [
    "### Usage of the Fetching Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28752d",
   "metadata": {},
   "source": [
    "As we said, `simple_history_log.py` will use a thread pool to fetch data using the `boto3` api. The script has no parameters exposed to command line. Most of the parameters appear as constants at the beginning of the file.\n",
    "\n",
    "\n",
    "To run the script you need:\n",
    "1. python3\n",
    "2. venv\n",
    "3. AWS CLI and credentials (see https://docs.aws.amazon.com/cli/latest/userguide/getting-started-prereqs.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8dd9c3",
   "metadata": {},
   "source": [
    "#### Setup Environment\n",
    "Make sure you have already set up the AWS on the machine.\n",
    "\n",
    "Create a `venv`:\n",
    "```bash\n",
    "python3 -m venv venv\n",
    "```\n",
    "\n",
    "If you're not already within the `venv`, activate it:\n",
    "```bash\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "Install pip requirements:\n",
    "\n",
    "```bash\n",
    "pip install -r pip_requirements.txt\n",
    "```\n",
    "\n",
    "Now you're ready to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7ed00",
   "metadata": {},
   "source": [
    "#### Running\n",
    "\n",
    "With the `venv` activated:\n",
    "```bash\n",
    "python simple_history_log.py\n",
    "```\n",
    "\n",
    "The scripts periodically saves the progress so you can interrupt it and continue where you left off (unless you wait too long and the `next_token` is expired).\n",
    "\n",
    "Note that the script will not save identical adjacent data points.\n",
    "\n",
    "Also note that the scripts saves the logs to a file called `spot_history_boto3.log`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb0eed",
   "metadata": {},
   "source": [
    "### Other Scripts\n",
    "\n",
    "\n",
    "There are also a few other scripts you can use. Here is a general list of a few of them:\n",
    " \n",
    "- `graphSpotPrice.py` - Will show graphs for the prices over time. takes the data from CSV\n",
    "- `compress_pickle.py` - Will pickle and compress the json file that the `simple_history_log.py` created (well, actually any other json too)\n",
    "- `decompress_pickle.py` - Decompress back to json\n",
    "- `get_int_json[.sh|.py]` - Downloads and deduplicates the the monthly statistical data of interruptions and savings from the spot advisor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a85364",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Directions\n",
    "\n",
    "### NN\n",
    "\n",
    "### Static Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ee9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
