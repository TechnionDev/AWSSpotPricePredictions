{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "# import dataset, network to train and metric to optimize\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, RecurrentNetwork, QuantileLoss\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load data: this is pandas dataframe with at least a column for\n",
    "# * the target (what you want to predict)\n",
    "# * the timeseries ID (which should be a unique string to identify each timeseries)\n",
    "# * the time of the observation (which should be a monotonically increasing integer)\n",
    "TRANSFORM_DATA = True\n",
    "if TRANSFORM_DATA:\n",
    "    raw_data = pd.read_csv('spotData.csv')\n",
    "    raw_data = raw_data.loc[raw_data['2021-11-15 16:40:32.509429'] != 'N/A*']#.head(128)\n",
    "    date_columns = [x for x in raw_data.columns if x.startswith('2021')]\n",
    "    not_date_columns = [x for x in raw_data.columns if not x.startswith('2021')]\n",
    "    raw_data = raw_data.melt(id_vars=not_date_columns, value_vars=date_columns, var_name='date', value_name='blabla').drop(columns=['blabla'])\n",
    "    raw_data.to_csv('data.csv', index=False)\n",
    "else:\n",
    "    raw_data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = raw_data.astype({\n",
    "    'Region': 'category',\n",
    "    'instanceType': 'category',\n",
    "    'major': 'category',\n",
    "    'minor': 'category',\n",
    "    'Type': 'category',\n",
    "    'OS': 'category',\n",
    "    'date': 'datetime64'\n",
    "})\n",
    "dates = {v: k for k, v in enumerate(data['date'].drop_duplicates().sort_values())}\n",
    "data['time_idx'] = data['date'].apply(lambda x: dates[x])\n",
    "# data['Price'] = pd.to_numeric(raw_data['Price'], errors='coerce').fillna(-1)\n",
    "data['Price'] = pd.to_numeric(raw_data['Price'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>instanceType</th>\n",
       "      <th>major</th>\n",
       "      <th>minor</th>\n",
       "      <th>Type</th>\n",
       "      <th>OS</th>\n",
       "      <th>Price</th>\n",
       "      <th>date</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us-east</td>\n",
       "      <td>a1.medium</td>\n",
       "      <td>a1</td>\n",
       "      <td>medium</td>\n",
       "      <td>generalCurrentGen</td>\n",
       "      <td>linux</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>2021-11-15 16:40:32.509429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us-east</td>\n",
       "      <td>a1.large</td>\n",
       "      <td>a1</td>\n",
       "      <td>large</td>\n",
       "      <td>generalCurrentGen</td>\n",
       "      <td>linux</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>2021-11-15 16:40:32.509429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us-east</td>\n",
       "      <td>a1.xlarge</td>\n",
       "      <td>a1</td>\n",
       "      <td>xlarge</td>\n",
       "      <td>generalCurrentGen</td>\n",
       "      <td>linux</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>2021-11-15 16:40:32.509429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us-east</td>\n",
       "      <td>a1.2xlarge</td>\n",
       "      <td>a1</td>\n",
       "      <td>2xlarge</td>\n",
       "      <td>generalCurrentGen</td>\n",
       "      <td>linux</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>2021-11-15 16:40:32.509429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us-east</td>\n",
       "      <td>a1.4xlarge</td>\n",
       "      <td>a1</td>\n",
       "      <td>4xlarge</td>\n",
       "      <td>generalCurrentGen</td>\n",
       "      <td>linux</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>2021-11-15 16:40:32.509429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610217</th>\n",
       "      <td>eu-south-1</td>\n",
       "      <td>m5d.metal</td>\n",
       "      <td>m5d</td>\n",
       "      <td>metal</td>\n",
       "      <td>hiMemCurrentGen</td>\n",
       "      <td>mswin</td>\n",
       "      <td>5.9431</td>\n",
       "      <td>2021-12-02 23:46:42.905937</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610218</th>\n",
       "      <td>eu-south-1</td>\n",
       "      <td>r5.metal</td>\n",
       "      <td>r5</td>\n",
       "      <td>metal</td>\n",
       "      <td>hiMemCurrentGen</td>\n",
       "      <td>linux</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>2021-12-02 23:46:42.905937</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610219</th>\n",
       "      <td>eu-south-1</td>\n",
       "      <td>r5.metal</td>\n",
       "      <td>r5</td>\n",
       "      <td>metal</td>\n",
       "      <td>hiMemCurrentGen</td>\n",
       "      <td>mswin</td>\n",
       "      <td>6.0158</td>\n",
       "      <td>2021-12-02 23:46:42.905937</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610220</th>\n",
       "      <td>eu-south-1</td>\n",
       "      <td>r5d.metal</td>\n",
       "      <td>r5d</td>\n",
       "      <td>metal</td>\n",
       "      <td>hiMemCurrentGen</td>\n",
       "      <td>linux</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>2021-12-02 23:46:42.905937</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610221</th>\n",
       "      <td>eu-south-1</td>\n",
       "      <td>r5d.metal</td>\n",
       "      <td>r5d</td>\n",
       "      <td>metal</td>\n",
       "      <td>hiMemCurrentGen</td>\n",
       "      <td>mswin</td>\n",
       "      <td>6.0158</td>\n",
       "      <td>2021-12-02 23:46:42.905937</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7610222 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Region instanceType major    minor               Type     OS  \\\n",
       "0           us-east    a1.medium    a1   medium  generalCurrentGen  linux   \n",
       "1           us-east     a1.large    a1    large  generalCurrentGen  linux   \n",
       "2           us-east    a1.xlarge    a1   xlarge  generalCurrentGen  linux   \n",
       "3           us-east   a1.2xlarge    a1  2xlarge  generalCurrentGen  linux   \n",
       "4           us-east   a1.4xlarge    a1  4xlarge  generalCurrentGen  linux   \n",
       "...             ...          ...   ...      ...                ...    ...   \n",
       "7610217  eu-south-1    m5d.metal   m5d    metal    hiMemCurrentGen  mswin   \n",
       "7610218  eu-south-1     r5.metal    r5    metal    hiMemCurrentGen  linux   \n",
       "7610219  eu-south-1     r5.metal    r5    metal    hiMemCurrentGen  mswin   \n",
       "7610220  eu-south-1    r5d.metal   r5d    metal    hiMemCurrentGen  linux   \n",
       "7610221  eu-south-1    r5d.metal   r5d    metal    hiMemCurrentGen  mswin   \n",
       "\n",
       "          Price                       date  time_idx  \n",
       "0        0.0084 2021-11-15 16:40:32.509429         0  \n",
       "1        0.0217 2021-11-15 16:40:32.509429         0  \n",
       "2        0.0341 2021-11-15 16:40:32.509429         0  \n",
       "3        0.0671 2021-11-15 16:40:32.509429         0  \n",
       "4        0.1343 2021-11-15 16:40:32.509429         0  \n",
       "...         ...                        ...       ...  \n",
       "7610217  5.9431 2021-12-02 23:46:42.905937       738  \n",
       "7610218  1.5998 2021-12-02 23:46:42.905937       738  \n",
       "7610219  6.0158 2021-12-02 23:46:42.905937       738  \n",
       "7610220  1.5998 2021-12-02 23:46:42.905937       738  \n",
       "7610221  6.0158 2021-12-02 23:46:42.905937       738  \n",
       "\n",
       "[7610222 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['date'] <= '2021-12-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the dataset, i.e. add metadata to pandas dataframe for the model to understand it\n",
    "max_encoder_length = 2 * 24 * 7\n",
    "max_prediction_length = 2 * 24 * 2\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    # data[data['date'] <= training_cutoff],#data[lambda x: x.date <= training_cutoff],\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx='time_idx',  # column name of time of observation\n",
    "    target='Price',  # column name of target to predict\n",
    "    group_ids=['Region', 'OS', 'instanceType'],  # column name(s) for timeseries IDs\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,  # how much history to use\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,  # how far to predict into future\n",
    "    # covariates static for a timeseries ID\n",
    "    static_categoricals=['major', 'minor', 'Type'],\n",
    "    # static_reals=[ ... ],\n",
    "    # covariates known and unknown in the future to inform prediction\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_known_reals=['time_idx'],\n",
    "    time_varying_unknown_reals=['Price'],\n",
    "    # target_normalizer=NaNLabelEncoder(add_nan=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create validation dataset using the same normalization techniques as for the training dataset\n",
    "#validation = TimeSeriesDataSet.from_dataset(training, data, min_prediction_idx=training.index.time.max() + 1, stop_randomization=True)\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# convert datasets to dataloaders for training\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=2)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8938664, 10298)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training), len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# create PyTorch Lighning Trainer with early stopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=1, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    gpus=1,  # run on CPU, if on multiple GPUs, use accelerator=\"ddp\"\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # 30 batches per epoch\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=TensorBoardLogger(\"lightning_logs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 64.0k\n"
     ]
    }
   ],
   "source": [
    "# define network to train - the architecture is mostly inferred from the dataset, so that only a few hyperparameters have to be set by the user\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    # dataset\n",
    "    training,\n",
    "    # architecture hyperparameters\n",
    "    hidden_size=32,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    # loss metric to optimize\n",
    "    loss=QuantileLoss(),\n",
    "    # logging frequency\n",
    "    log_interval=2,\n",
    "    # optimizer parameters\n",
    "    learning_rate=0.03,\n",
    "    reduce_on_plateau_patience=4\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n",
    "\n",
    "# # find the optimal learning rate\n",
    "# res = trainer.tuner.lr_find(\n",
    "#     tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, early_stop_threshold=1000.0, max_lr=0.3,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # and plot the result - always visually confirm that the suggested learning rate makes sense\n",
    "# print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "# fig = res.plot(show=True, suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.4 K \n",
      "3  | prescalers                         | ModuleDict                      | 96    \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 2.4 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 3.8 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.8 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K \n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K \n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K \n",
      "20 | output_layer                       | Linear                          | 231   \n",
      "----------------------------------------------------------------------------------------\n",
      "64.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "64.0 K    Total params\n",
      "0.256     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0c4c5313d045c5921235d93ce3cf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit the model on the data - redefine the model with the correct learning rate if necessary\n",
    "trainer.fit(\n",
    "    tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_MAE': 1.6829328330913995e-07,\n",
      " 'val_MAPE': 2.2160266155424324e-07,\n",
      " 'val_RMSE': 5.422189133241773e-07,\n",
      " 'val_SMAPE': 2.2160266155424324e-07,\n",
      " 'val_loss': 7.177621341725171e-08}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 7.177621341725171e-08,\n",
       "  'val_SMAPE': 2.2160266155424324e-07,\n",
       "  'val_MAE': 1.6829328330913995e-07,\n",
       "  'val_RMSE': 5.422189133241773e-07,\n",
       "  'val_MAPE': 2.2160266155424324e-07}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(tft, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our_prediction_mae=1.6422191606579872e-07\n",
      "baseline_prediction_mae=0.0\n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import Baseline\n",
    "\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "our_prediction_mae = (actuals - predictions).abs().mean()\n",
    "print(f'our_prediction_mae={our_prediction_mae}')\n",
    "\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "baseline_prediction_mae = (actuals - baseline_predictions).abs().mean().item()\n",
    "print(f'baseline_prediction_mae={baseline_prediction_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69833, 81)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
